import streamlit as st
import pandas as pd
import io
from datetime import date

from database_pg import (
    init_db,
    insert_email,
    search_emails,
    get_database_size_gb
)

from scraper_email import search_and_extract_emails

# ============================
# INITIALIZE DATABASE
# ============================
init_db()

# ============================
# PAGE CONFIG
# ============================
st.set_page_config(
    page_title="Email ID Extractor â€” Digmar",
    layout="wide"
)

# ============================
# SIDEBAR
# ============================
st.sidebar.title("ğŸ“‚ Navigation")

# Show Neon DB usage
try:
    db_size = get_database_size_gb()
    st.sidebar.info(f"ğŸ—„ Neon DB Usage: {db_size} GB / 0.5 GB")
except:
    st.sidebar.warning("âš ï¸ DB size unavailable")

page = st.sidebar.radio(
    "Select Option",
    ["ğŸ“§ Extract Emails", "ğŸ—„ View Database"]
)

# ============================
# ğŸ“§ EXTRACT EMAILS
# ============================
if page == "ğŸ“§ Extract Emails":

    st.title("ğŸ“§ Email ID Extractor â€” ANVIA")

    uploaded = st.file_uploader(
        "ğŸ“‚ Upload Excel (.xlsx) with **keyword** column",
        type=["xlsx"]
    )

    if uploaded is not None:
        df = pd.read_excel(uploaded)

        if "keyword" not in df.columns:
            st.error("âŒ Excel must contain a column named **keyword**")
        else:
            st.success("âœ” File loaded successfully")

            if st.button("ğŸš€ Start Email Extraction"):
                progress = st.progress(0)
                all_results = []

                keywords = df["keyword"].dropna().unique().tolist()
                total = len(keywords)

                for i, keyword in enumerate(keywords):
                    st.write(f"ğŸ” Searching: **{keyword}**")

                    extracted = search_and_extract_emails(keyword)

                    if not extracted:
                        st.info("No email IDs found")

                    for email, source in extracted:
                        # INSERT ONLY IF NOT EXISTS (handled in DB)
                        inserted, truncated = insert_email(keyword, email, source)
                        if truncated:
                            st.warning("âš ï¸ Database reached storage limit. Old data was auto-cleared.")

                        if inserted:
                            all_results.append({
                                "keyword": keyword,
                                "email": email,
                                "source": source
                            })

                    progress.progress((i + 1) / total)

                if all_results:
                    out_df = pd.DataFrame(all_results)
                    st.subheader("âœ… Newly Stored Emails")
                    st.dataframe(out_df, use_container_width=True)

                    buffer = io.BytesIO()
                    out_df.to_excel(buffer, index=False)
                    buffer.seek(0)

                    st.download_button(
                        label="ğŸ“¥ Download New Emails (Excel)",
                        data=buffer,
                        file_name="new_emails.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                else:
                    st.warning("âš ï¸ All extracted emails already exist in database")

# ============================
# ğŸ—„ VIEW DATABASE
# ============================
if page == "ğŸ—„ View Database":

    st.title("ğŸ—„ Search Stored Email Database")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        keyword = st.text_input("ğŸ” Keyword")

    with col2:
        date_from = st.date_input("ğŸ“… From Date", value=date.today())

    with col3:
        date_to = st.date_input("ğŸ“… To Date", value=date.today())

    with col4:
        source = st.text_input("ğŸ” Source URL")

    if st.button("ğŸ” Search Database"):
        df = search_emails(
            keyword=keyword,
            source=source,
            date_from=str(date_from),
            date_to=str(date_to)
        )

        if df.empty:
            st.warning("âŒ No data found")
        else:
            st.success(f"âœ” Found {len(df)} records")

            df_display = df[
                ["id", "keyword", "email", "source", "created_at"]
            ]

            st.dataframe(df_display, use_container_width=True)

            buffer = io.BytesIO()
            df_display.to_excel(buffer, index=False)
            buffer.seek(0)

            st.download_button(
                label="ğŸ“¥ Download Filtered Data (Excel)",
                data=buffer,
                file_name="filtered_emails.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
